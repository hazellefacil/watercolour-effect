{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os \n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dropout\n",
    "from keras.initializers import RandomNormal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image_file):\n",
    "    #decode into uint8 tensor\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "\n",
    "    #split into photo + painting \n",
    "    w = tf.shape(image)[1]\n",
    "    w = w // 2\n",
    "    input_image = image[:,w:,:]\n",
    "    real_image = image[:,:w,:]\n",
    "\n",
    "    #convert both images to float32 tensors \n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)\n",
    "\n",
    "    return input_image, real_image \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(image_shape):\n",
    "\n",
    "    # stddev can be edited \n",
    "    initializer = tf.random_normal_initializer(0.0, 0.05)\n",
    "\n",
    "    inp_img = Input(shape=image_shape, name='input_image')\n",
    "    target_img = Input(shape=image_shape, name='target_image')\n",
    "\n",
    "    merged = Concatenate()([inp_img,target_img])\n",
    "\n",
    "    # adapted from 'Image-to-Image Translation with Conditional Adversarial Networks' - Isola, UC Berkeley\n",
    "    # C64-C128-C256-C512\n",
    "    \n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=initializer)(merged)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=initializer)(merged)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=initializer)(merged)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=initializer)(merged)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "    # patch output\n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "    model = Model([inp_img,target_img], patch_out)\n",
    "    out = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', loss_weights=[0.5])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(size, n_filters, apply_batchnorm=True):\n",
    "\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    downsample = Conv2D(n_filters, (4,4), strides = (2,2), padding = 'same', kernel_initializer = init)(size)\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        downsample = BatchNormalization()(downsample, training=True)\n",
    "\n",
    "    downsample = LeakyReLU(alpha=0.2)(downsample)\n",
    "    return downsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(size, skip, n_filters, apply_dropout=False):\n",
    "\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    upsample = Conv2DTranspose(n_filters, (4,4), strides = (2,2), padding = 'same', kernel_initializer = init)(size)\n",
    "    upsample = BatchNormalization()(upsample, training=True)\n",
    "    if dropout:\n",
    "        upsample = Dropout(0.5)(upsample,training=True)\n",
    "    \n",
    "    upsample = Concatenate()([upsample,skip])\n",
    "    upsample = Activation('reLU')(upsample)\n",
    "    return upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(image_shape)\n",
    "\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # adapted from 'Image-to-Image Translation with Conditional Adversarial Networks' - Isola, UC Berkeley\n",
    "    # C64-C128-C256-C512\n",
    "\n",
    "    inp_img = Input(shape = image_shape)\n",
    "    e1 = encoder(inp_img, 64, apply_batchnorm=False)\n",
    "    e2 = encoder(e1, 128) \n",
    "    e3 = encoder(e2, 256) \n",
    "    e4 = encoder(e3, 512) \n",
    "    e5 = encoder(e4, 512)\n",
    "    e6 = encoder(e5, 512)\n",
    "    e7 = encoder(e6, 512)\n",
    "\n",
    "    bottleneck = Conv2D(512, (4,4), strides = 2, padding = 'same', kernel_initializer=init)(e7)\n",
    "    bottleneck = Activation('reLU')(bottleneck)\n",
    "\n",
    "    d1 = decoder(bottleneck, e7,512)\n",
    "    d2 = decoder(d1, e6, 512)\n",
    "    d3 = decoder(d2, e5, 512)\n",
    "    d4 = decoder(d3, e4, 512, dropout=False)\n",
    "    d5 = decoder(d4, e3, 256, dropout=False)\n",
    "    d6 = decoder(d5, e2, 128, dropout=False)\n",
    "    d7 = decoder(d6, e1, 64, dropout=False)\n",
    "\n",
    "\tg = Conv2DTranspose(image_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7) \n",
    "\tout_image = Activation('tanh')(g) \n",
    "\n",
    "    model = Model(in_image, out_image)\n",
    "    return model\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
